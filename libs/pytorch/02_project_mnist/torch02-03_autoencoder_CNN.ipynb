{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (CNN) Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Class for logging trainings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataLogger():\n",
    "    '''Helper class that stores informatoion during training'''\n",
    "    def __init__(self) -> None:\n",
    "        self.ls_losses:List[float] = []\n",
    "\n",
    "        '''important for visualization'''\n",
    "        self.ls_epochs:List[int]    = []\n",
    "        self.ls_imgs:List[torch.Tensor]  = []\n",
    "        self.ls_recimgs:List[torch.Tensor]  = [] \n",
    "        pass "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss per epoch\n",
    "def plot_losses(losses) -> None:\n",
    "    '''plots loss per epoch'''\n",
    "    epochs = range(1, len(losses)+1)\n",
    "\n",
    "    xticks = range(min(epochs), max(epochs)+1) # transforms into integer\n",
    "\n",
    "    plt.plot(epochs, losses)\n",
    "    plt.title('Loss per epoch'), plt.ylabel('Loss'),  plt.xlabel('Epoch')\n",
    "    plt.xticks(xticks)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADER\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))\n",
    "    ])\n",
    "\n",
    "data_train = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "data_test  = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(data_train, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(data_test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# DATA: look at pixels value range (important for activation function in decoder)\n",
    "imgs, labels = next(iter(train_dataloader))\n",
    "\n",
    "print( torch.min(imgs)  , torch.max(imgs) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class: Autoencoder (Conv.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "        Normal:\n",
      "            [64, 1, 28, 28]\n",
      "        Convolutional:\n",
      "            [64, 16, 14, 14], \n",
      "            [64, 32, 7, 7], \n",
      "            [64, 64, 1, 1],\n",
      "        Tranpose:    \n",
      "            [64, 32, 7, 7]\n",
      "            [64, 16, 14, 14], \n",
      "            [64, 1, 28, 28],    \n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine output size\n",
    "conv1 = nn.Conv2d(1, 16, 3, stride=2, padding=1)\n",
    "conv2 = nn.Conv2d(16, 32, 3, stride=2, padding=1)\n",
    "conv3 = nn.Conv2d(32, 64, 7)\n",
    "\n",
    "tconv1 = nn.ConvTranspose2d(64, 32, 7)\n",
    "tconv2 = nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1)\n",
    "tconv3 = nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "\n",
    "imgs, _ = next(iter(train_dataloader))\n",
    "\n",
    "# PRINTS\n",
    "print(f'''\n",
    "\n",
    "        Normal:\n",
    "            {list(imgs.size())}\n",
    "        Convolutional:\n",
    "            {list(conv1(imgs).size())}, \n",
    "            {list(conv2(conv1(imgs)).size())}, \n",
    "            {list(conv3(conv2(conv1(imgs))).size())},\n",
    "        Tranpose:    \n",
    "            {list(tconv1(conv3(conv2(conv1(imgs)))).size())}\n",
    "            {list(tconv2(tconv1(conv3(conv2(conv1(imgs))))).size())}, \n",
    "            {list(tconv3(tconv2(tconv1(conv3(conv2(conv1(imgs)))))).size())},    \n",
    "            \n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv1, nn.ReLU(),\n",
    "            conv2, nn.ReLU(),\n",
    "            conv3, \n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            tconv1, nn.ReLU(),\n",
    "            tconv2, nn.ReLU(),\n",
    "            tconv3, \n",
    "            nn.Sigmoid() # making pixel in range [0,1] (gray scaled)\n",
    "        )\n",
    "\n",
    "        pass \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def train(epochs: int, model: nn.Module, dataloader: DataLoader, optimizer: optim.Optimizer, criterion) -> TrainDataLogger:\n",
    "    n_batches = len(dataloader)\n",
    "    train_data: TrainDataLogger = TrainDataLogger()\n",
    "    \n",
    "    model.train()\n",
    "    for i_epoch in range(epochs):\n",
    "        loss_epoch = 0\n",
    "        for i_batch, (X,_) in enumerate(dataloader):\n",
    "\n",
    "            # adjust shahpe of tensor, so that it fits into first layer\n",
    "            # X = X.reshape(-1, 28*28) \n",
    "\n",
    "            # pred (encode & decode)\n",
    "            recon = model(X)\n",
    "\n",
    "            # loss (how much difference between each pixel)\n",
    "            loss = criterion(recon, X)\n",
    "            if math.isnan(loss): \n",
    "                print(f'NAN @ epoch={i_epoch}, batch={i_batch}')\n",
    "                return\n",
    "            loss_epoch += loss\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print\n",
    "            if i_batch % 250 == 0:\n",
    "                print(f'Epoch\\t{i_epoch+1}/{epochs}\\t\\tBatch\\t{i_batch}/{n_batches}\\t({(100. * i_batch / n_batches):.1f}%)\\t\\tLoss\\t{loss:.4f}')\n",
    "        \n",
    "        # Save training data per epoch\n",
    "        train_data.ls_losses.append(loss_epoch / n_batches)\n",
    "        train_data.ls_imgs.append(X)\n",
    "        train_data.ls_recimgs.append(recon)\n",
    "        train_data.ls_epochs.append(i_epoch)\n",
    "\n",
    "\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model:nn.Module, dataloader:DataLoader, criterion) -> float:\n",
    "    model.eval()\n",
    "\n",
    "    n_batches = len(dataloader)\n",
    "    loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (X,_) in enumerate(dataloader):\n",
    "           # X = X.reshape(-1,  28*28)\n",
    "\n",
    "            # pred \n",
    "            recon = model(X)\n",
    "\n",
    "            # loss\n",
    "            loss += criterion(recon, X)\n",
    "\n",
    "        loss = loss / n_batches\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder_Conv() # Autoencoder_Linear()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch\t1/3\t\tBatch\t0/938\t(0.0%)\t\tLoss\t1.8554\n",
      "NAN @ epoch=0, batch=122\n"
     ]
    }
   ],
   "source": [
    "train_data:TrainDataLogger = train(3, model, train_dataloader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'ls_losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\heuer\\GitHub\\tutorial_Python\\libs\\pytorch\\02_project_mnist\\torch02-03_autoencoder_CNN.ipynb Cell 20\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/heuer/GitHub/tutorial_Python/libs/pytorch/02_project_mnist/torch02-03_autoencoder_CNN.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plot_losses(torch\u001b[39m.\u001b[39mTensor(train_data\u001b[39m.\u001b[39;49mls_losses))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'ls_losses'"
     ]
    }
   ],
   "source": [
    "plot_losses(torch.Tensor(train_data.ls_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_dataloader,  criterion).item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = len(train_data.ls_epochs)\n",
    "\n",
    "num_imgs_per_row = 9 \n",
    "num_rows = 2\n",
    "\n",
    "\n",
    "for i_epoch in range(0, num_epochs):\n",
    "    plt.figure(figsize=(9,2))\n",
    "    plt.gray()\n",
    "    imgs    =  train_data.ls_imgs[i_epoch].detach().numpy()\n",
    "    recimgs  = train_data.ls_recimgs[i_epoch].detach().numpy()\n",
    "\n",
    "    for i, imgs_batch in enumerate(imgs):\n",
    "        if i >= num_imgs_per_row : break\n",
    "\n",
    "        plt.subplot(num_rows,num_imgs_per_row, i+1)\n",
    "        imgs_batch = imgs_batch.reshape(-1, 28, 28)\n",
    "        plt.imshow(imgs_batch[0])\n",
    "\n",
    "    for i, imgs_batch in enumerate(recimgs):\n",
    "        if i >= num_imgs_per_row : break\n",
    "\n",
    "        plt.subplot(num_rows,num_imgs_per_row, i+1+num_imgs_per_row)\n",
    "        imgs_batch = imgs_batch.reshape(-1, 28, 28)\n",
    "        plt.imshow(imgs_batch[0])\n",
    "\n",
    "plt.show()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
